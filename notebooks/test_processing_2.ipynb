{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Общие методы](#toc1_)    \n",
    "  - [Обработка дат](#toc1_1_)    \n",
    "  - [Обработка уровней орагнизации](#toc1_2_)    \n",
    "  - [Обработка КБК](#toc1_3_)    \n",
    "  - [Поиск и замена плохих адресов](#toc1_4_)    \n",
    "  - [Декомпозиция адресов](#toc1_5_)    \n",
    "- [Метод для обработки ORG](#toc2_)    \n",
    "- [Метод для обработки contract](#toc3_)    \n",
    "- [Класс для обработки данных](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/.cache/pypoetry/virtualenvs/contract-Fr7eyqb1-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from tqdm.auto import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from pullenti.address.AddressService import AddressService\n",
    "\n",
    "AddressService.set_server_connection(\"http://localhost:2222\")\n",
    "\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "# Сброс ограничений на число столбцов\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# Сброс ограничений на количество символов в записи\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Общие методы](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw_data/contract/2014/0.csv\", sep=\"|\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_contract', 'address_customer', 'full_name_customer',\n",
       "       'short_name_customer', 'code', 'code_type', 'id_customer',\n",
       "       'inn_customer', 'kpp_customer', 'code_form_org', 'okpo_code',\n",
       "       'municipal_code', 'budget_name', 'extrabudget_name', 'budget_level',\n",
       "       'contract_status', 'notice', 'ikz_code', 'id_contract_electronic',\n",
       "       'unique_number_plan', 'method_determinig_supplier', 'date_summarizing',\n",
       "       'date_posting', 'grouds_single_supplier', 'document_details',\n",
       "       'info_support', 'date_contract', 'date_performance',\n",
       "       'date_contract_registry', 'date_update_registry',\n",
       "       'date_start_performance', 'date_end_performance', 'contract_item',\n",
       "       'contract_price', 'contract_price_nds', 'prepayment_amount',\n",
       "       'performance_security', 'size_performance_quality', 'warranty_period',\n",
       "       'place_performance', 'full_name_supplier', 'inn_supplier',\n",
       "       'kpp_supplier', 'code_okpo_supplier', 'date_registration_supplier',\n",
       "       'country_supplier', 'code_country_supplier', 'address_supplier',\n",
       "       'postal_address_supplier', 'contact', 'status_supplier', 'kbk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../data/raw_data/contract/2014/\"\n",
    "# for file_name in tqdm(os.listdir(path)):\n",
    "#     file_name = os.path.join(path, file_name)\n",
    "#     df = pd.read_csv(file_name, sep=\"|\", dtype=\"str\")\n",
    "#     df.columns = [\n",
    "#         \"number_contract\",\n",
    "#         \"address_customer\",\n",
    "#         \"full_name_customer\",\n",
    "#         \"short_name_customer\",\n",
    "#         \"code\",\n",
    "#         \"code_type\",\n",
    "#         \"id_customer\",\n",
    "#         \"inn_customer\",\n",
    "#         \"kpp_customer\",\n",
    "#         \"code_form_org\",\n",
    "#         \"okpo_code\",\n",
    "#         \"municipal_code\",\n",
    "#         \"budget_name\",\n",
    "#         \"extrabudget_name\",\n",
    "#         \"budget_level\",\n",
    "#         \"contract_status\",\n",
    "#         \"notice\",\n",
    "#         \"ikz_code\",\n",
    "#         \"id_contract_electronic\",\n",
    "#         \"unique_number_plan\",\n",
    "#         \"method_determinig_supplier\",\n",
    "#         \"date_summarizing\",\n",
    "#         \"date_posting\",\n",
    "#         \"grouds_single_supplier\",\n",
    "#         \"document_details\",\n",
    "#         \"info_support\",\n",
    "#         \"date_contract\",\n",
    "#         \"date_performance\",\n",
    "#         \"date_contract_registry\",\n",
    "#         \"date_update_registry\",\n",
    "#         \"date_start_performance\",\n",
    "#         \"date_end_performance\",\n",
    "#         \"contract_item\",\n",
    "#         \"contract_price\",\n",
    "#         \"contract_price_nds\",\n",
    "#         \"prepayment_amount\",\n",
    "#         \"performance_security\",\n",
    "#         \"size_performance_quality\",\n",
    "#         \"warranty_period\",\n",
    "#         \"place_performance\",\n",
    "#         \"full_name_supplier\",\n",
    "#         \"inn_supplier\",\n",
    "#         \"kpp_supplier\",\n",
    "#         \"code_okpo_supplier\",\n",
    "#         \"date_registration_supplier\",\n",
    "#         \"country_supplier\",\n",
    "#         \"code_country_supplier\",\n",
    "#         \"address_supplier\",\n",
    "#         \"postal_address_supplier\",\n",
    "#         \"contact\",\n",
    "#         \"status_supplier\",\n",
    "#         \"kbk\",\n",
    "#     ]\n",
    "#     df.to_csv(file_name, sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Обработка дат](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_month = {\n",
    "    \"января\": \"01\",\n",
    "    \"февраля\": \"02\",\n",
    "    \"марта\": \"03\",\n",
    "    \"апреля\": \"04\",\n",
    "    \"мая\": \"05\",\n",
    "    \"июня\": \"06\",\n",
    "    \"июля\": \"07\",\n",
    "    \"августа\": \"08\",\n",
    "    \"сентября\": \"09\",\n",
    "    \"октября\": \"10\",\n",
    "    \"ноября\": \"11\",\n",
    "    \"декабря\": \"12\",\n",
    "}\n",
    "\n",
    "\n",
    "def date_extract(date: str):\n",
    "    if not date or date == \"--.--.----\" or type(date) != str:\n",
    "        return None\n",
    "\n",
    "    date = date.replace(\"Загрузка ...\", \"\").strip()\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date, \"%d.%m.%Y\").date()\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date[:10], \"%d.%m.%Y\").date()\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date.split()[0], \"%d.%m.%Y\").date()\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    for key, value in dict_month.items():\n",
    "        if key in date:\n",
    "            date = date.replace(key, value)\n",
    "            date = \".\".join(date.split())\n",
    "\n",
    "    date = date.split(\".\")\n",
    "\n",
    "    if len(date) == 2:\n",
    "        date = \".\".join([\"01\"] + date)\n",
    "        return datetime.datetime.strptime(date[:10], \"%d.%m.%Y\").date()\n",
    "    # логи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Обработка уровней орагнизации](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_local = [\"муниципальный уровень\", \"местный бюджет\"]\n",
    "list_sub = [\n",
    "    \"уровень субъекта рф\",\n",
    "    \"бюджет субъекта российской федерации\",\n",
    "    \"бюджет территориального государственного внебюджетного фонда\",\n",
    "    \"бюджет территориального государственного внебюджетного фонда\",\n",
    "]\n",
    "list_fed = [\n",
    "    \"федеральный уровень\",\n",
    "    \"федеральный бюджет\",\n",
    "    \"бюджет пенсионного фонда российской федерации\",\n",
    "    \"бюджет федерального фонда обязательного медицинского страхования\",\n",
    "    \"бюджет фонда социального страхования российской федерации\",\n",
    "]\n",
    "\n",
    "list_fed_2 = [\n",
    "    \"войскавая\",\n",
    "    \"войсковая\",\n",
    "    \"воениз\",\n",
    "    \"федеральн\",\n",
    "    \"район водных путей и судоходства\",\n",
    "    \"следвест\",\n",
    "    \"пенсион\",\n",
    "    \"росган\",\n",
    "    \"фгбу\",\n",
    "    \"всероссийс\",\n",
    "    \" фбу\",\n",
    "    \"прокурату\",\n",
    "    \"университ\",\n",
    "    \"научно-исследователь\",\n",
    "    \"государственное научное учреждение\",\n",
    "    \"росграниц\",\n",
    "    \"российской академии наук\",\n",
    "    \"внутренних дел\",\n",
    "    \"мвд\",\n",
    "    \"суд\",\n",
    "    \"управление министерства промышленности\",\n",
    "    \"торговли российской федерации\",\n",
    "    \"таможенный пост\",\n",
    "    \"российской федерации\",\n",
    "    \"таможня\",\n",
    "    \"таможенного\",\n",
    "    \"российская академия образования\",\n",
    "    \"российская академия образования\",\n",
    "    \"российская академия художеств\",\n",
    "]\n",
    "\n",
    "list_local_2 = [\n",
    "    \"городская администрация\",\n",
    "    \"муниципал\",\n",
    "    \"школа\",\n",
    "    \"детский сад\",\n",
    "    \"городского поселения\",\n",
    "    \"городского округа\",\n",
    "    \"администрация рабочего поселка\",\n",
    "    \"совет\",\n",
    "    \"управление образованием администрации г\",\n",
    "    \"поселок\",\n",
    "    \"поселк\",\n",
    "    \"частное учереждение\",\n",
    "    \"администрации зато\",\n",
    "    \"администрация пгт\",\n",
    "    \"территориальная избирательная комиссия\",\n",
    "    \"районный исполнительный комитет\",\n",
    "]\n",
    "list_sub_2 = [\n",
    "    \"центр занятости населения\",\n",
    "    \"област\",\n",
    "    \"республи\",\n",
    "    \"края\",\n",
    "    \"край\",\n",
    "    \"краев\",\n",
    "    \"города\",\n",
    "    \"автоном\",\n",
    "    \"oбластное\",\n",
    "    \"здравоохране\",\n",
    "    \"больниц\",\n",
    "    \"родильный дом\",\n",
    "    \"профессиональн\",\n",
    "    \"детский дом\",\n",
    "    \"дом-интернат\",\n",
    "    \"социальн\",\n",
    "    \"поликлиник\",\n",
    "    \"больниц\",\n",
    "    \"государственное бюджетное общеобразовательное учреждение\",\n",
    "    \"государственное бюджетное образовательное учреждение\",\n",
    "    \"медико-санитарная часть\",\n",
    "    \"московское государственное унитарное предприятие\",\n",
    "    \"учреждение культуры города\",\n",
    "    \"государственное бюджетное учреждение культуры\",\n",
    "    \"центр социального обслуживания\",\n",
    "    \"социального обслуживания граждан\",\n",
    "    \"стоматологическая поликлиника\",\n",
    "    \"центр для детей-сирот и детей\",\n",
    "    \"санкт-петербур\",\n",
    "    \"фонд социального страхования российской федерации\",\n",
    "    \"государственное бюджетное учреждение\",\n",
    "    \"инспекция труда\",\n",
    "    \"региональный\",\n",
    "]\n",
    "list_anothe = [\n",
    "    \"акционерное общество\",\n",
    "    \"завод\",\n",
    "    \"акционерное московское общество\",\n",
    "    \"общество с ограниченной ответственностью\",\n",
    "    \"частное\",\n",
    "    \"комбинат\",\n",
    "    \"ооо \",\n",
    "]\n",
    "list_fed_3 = []\n",
    "list_sub_3 = [\"ветеринар\", \"колледж\"]\n",
    "list_local_3 = [\n",
    "    \"района\",\n",
    "    \"сельск\",\n",
    "    \"районное управление образованием\",\n",
    "    \"районное бюджетное учреждение\",\n",
    "    \"мбу \",\n",
    "    \"городской Исполнительный комитет\",\n",
    "    \"городская избирательная комиссия\",\n",
    "]\n",
    "\n",
    "inn_sub = {\n",
    "    \"7727795994\": 'Государственное бюджетное научное учреждение \"Московский институт развития образования\"',\n",
    "    \"4205050521\": 'государственное учреждение \"Кузбасспассажиравтотранс\"',\n",
    "    \"1001036026\": 'БЮДЖЕТНОЕ УЧРЕЖДЕНИЕ \"ЦЕНТР КУЛЬТУРНЫХ ИНИЦИАТИВ\" (АГЕНТСТВО \"КУЛЬТУРНАЯ СЕТЬ КАРЕЛИИ\")',\n",
    "    \"2309102153\": \"ГУП КК Кубаньфармация\",\n",
    "}\n",
    "inn_fed = {\n",
    "    \"7704193182\": \"Региональное оперативно-поисковое управление\",\n",
    "    \"6672239827\": 'ЛИНЕЙНЫЙ ОТДЕЛ МИНИСТЕРСТВА ВНУТРЕННИХ ДЕЛ РОССИЙСКОЙ ФЕДЕРАЦИИ В АЭРОПОРТУ \"КОЛЬЦОВО',\n",
    "}\n",
    "inn_mun = {\n",
    "    \"3509009509\": 'БЮДЖЕТНОЕ УЧРЕЖДЕНИЕ \"КОММУНАЛЬЩИК\"',\n",
    "    \"3511005766\": 'БЮДЖЕТНОЕ УЧРЕЖДЕНИЕ КУЛЬТУРЫ \"КИРИЛЛОВСКИЙ КИНОДОСУГОВЫЙ ЦЕНТР\"',\n",
    "    \"4506004871\": \"Управление по делам образования, культуры, молодежи и спорта\",\n",
    "}\n",
    "inn_another = {\"1633002328\": 'ДЕТСКИЙ ОЗДОРОВИТЕЛЬНЫЙ ЛАГЕРЬ \"ЧАЙКА\"'}\n",
    "\n",
    "name_for_result = [\"местный\", \"субъектовый\", \"федеральный\", \"иное\"]\n",
    "\n",
    "\n",
    "def fillna_organization_level(budget_level: str, full_name_customer: str, inn_customer: str):\n",
    "    if type(budget_level) != str:\n",
    "        budget_level = None\n",
    "    elif type(budget_level) == str:\n",
    "        budget_level = budget_level.lower()\n",
    "\n",
    "    if type(full_name_customer) != str:\n",
    "        full_name_customer = None\n",
    "    elif type(full_name_customer) == str:\n",
    "        full_name_customer = full_name_customer.lower()\n",
    "\n",
    "    if type(inn_customer) != str:\n",
    "        inn_customer = None\n",
    "\n",
    "    if budget_level:\n",
    "        for list_name, name in zip(\n",
    "            [list_local, list_sub, list_fed], [\"местный\", \"субъектовый\", \"федеральный\"]\n",
    "        ):\n",
    "            for name_trigger in list_name:\n",
    "                if name_trigger.lower() in budget_level:\n",
    "                    return name\n",
    "\n",
    "    # если не получилось выделить данные из budget_level попробуем сделать это с full_name_customer\n",
    "    if full_name_customer:\n",
    "        for list_name, name in zip(\n",
    "            [list_fed_2, list_local_2, list_sub_2, list_anothe],\n",
    "            [\"федеральный\", \"местный\", \"субъектовый\", \"иное\"],\n",
    "        ):\n",
    "            for name_trigger in list_name:\n",
    "                if name_trigger.lower() in full_name_customer:\n",
    "                    return name\n",
    "\n",
    "        for list_name, name in zip(\n",
    "            [list_fed_3, list_local_3, list_sub_3],\n",
    "            [\"федеральный\", \"местный\", \"субъектовый\", \"иное\"],\n",
    "        ):\n",
    "            for name_trigger in list_name:\n",
    "                if name_trigger.lower() in full_name_customer:\n",
    "                    return name\n",
    "\n",
    "        if (\n",
    "            \"администрац\" in full_name_customer\n",
    "            or \"комитет по управлению имуществом\" in full_name_customer\n",
    "        ) and not all(\n",
    "            [\n",
    "                i in full_name_customer\n",
    "                for i in [\"моксв\", \"севастопол\" \"президент\", \"санкт-петербур\"]\n",
    "            ]\n",
    "        ):\n",
    "            return \"местный\"\n",
    "\n",
    "        if \"городская дума\" in full_name_customer and \"моксв\" not in full_name_customer:\n",
    "            return \"местный\"\n",
    "\n",
    "    if inn_customer:\n",
    "        for inn_dict, name in zip(\n",
    "            [inn_mun, inn_sub, inn_fed, inn_another],\n",
    "            [\"местный\", \"субъектовый\", \"федеральный\", \"иное\"],\n",
    "        ):\n",
    "            for inn in inn_dict.keys():\n",
    "                if inn == inn_customer:\n",
    "                    return name\n",
    "    # добавить логги\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Обработка КБК](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbk_type = pd.read_excel(\"../data/kbk.xlsx\", sheet_name=\"type\", dtype=\"str\")\n",
    "kbk_np = pd.read_excel(\"../data/kbk.xlsx\", sheet_name=\"np\", dtype=\"str\")\n",
    "kbk_section = pd.read_excel(\"../data/kbk.xlsx\", sheet_name=\"section\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_kbk(kbk, year):\n",
    "    dict_kbk = {\n",
    "        \"code_main_admin\": None,\n",
    "        \"code_section_sub\": None,\n",
    "        \"code_direction_expenses\": None,\n",
    "        \"code_type_expenses\": None,\n",
    "        \"code_national_project\": None,\n",
    "        \"value_code_section\": None,\n",
    "        \"value_code_sub\": None,\n",
    "        \"value_code_type_expenses\": None,\n",
    "        \"name_national_project\": None,\n",
    "        \"name_fed_national_project\": None,\n",
    "    }\n",
    "    if not kbk or type(kbk) != str:\n",
    "        return dict_kbk\n",
    "\n",
    "    if len(kbk) == 3 or kbk[:-3] == \"0\" * 17:\n",
    "        code_type_expenses = kbk[-3:]\n",
    "        value_code_type_expenses = kbk_type.loc[\n",
    "            kbk_type.code == code_type_expenses, \"mean\"\n",
    "        ].to_list()\n",
    "\n",
    "        if len(value_code_type_expenses):\n",
    "            dict_kbk[\"value_code_type_expenses\"] = value_code_type_expenses[0]\n",
    "        else:\n",
    "            pass\n",
    "            # логи\n",
    "        dict_kbk[\"code_type_expenses\"] = code_type_expenses\n",
    "        return dict_kbk\n",
    "\n",
    "    elif len(kbk) == 20:\n",
    "        kbk_search = re.compile(r\"(\\S\\S\\S)(\\S\\S\\S\\S)(\\S\\S\\S\\S\\S\\S\\S\\S\\S\\S)(\\S\\S\\S)\")\n",
    "        kbk_find = kbk_search.search(kbk)\n",
    "\n",
    "        # код главного распоредителя бюджетных средств\n",
    "        code_main_admin = kbk_find.group(1)\n",
    "        # print('Код ГРС:', code_main_admin)\n",
    "        # код раздела и подраздела\n",
    "        code_section_sub = kbk_find.group(2)\n",
    "        # print('Код раздела и подраздела:', code_section_sub)\n",
    "        # код целевой статьи\n",
    "        code_direction_expenses = kbk_find.group(3)\n",
    "        # print('Код целевой статьи:', code_direction_expenses)\n",
    "        # код вида расходов\n",
    "        code_type_expenses = kbk_find.group(4)\n",
    "        # print('Код вида расходов:', code_type_expenses)\n",
    "        # код национального проекта\n",
    "        code_national_project = (\n",
    "            code_direction_expenses[3:5] if not code_direction_expenses[3].isdigit() else None\n",
    "        )\n",
    "        # print('Код национального проекта:', code_national_project)\n",
    "\n",
    "        value_code_section = kbk_section.loc[\n",
    "            (kbk_section.year == year) & (kbk_section.code == code_section_sub[:2]), \"mean\"\n",
    "        ].to_list()\n",
    "        if len(value_code_section):\n",
    "            dict_kbk[\"value_code_section\"] = value_code_section[0]\n",
    "        else:\n",
    "            pass\n",
    "        # print('value_code_section:', value_code_section)\n",
    "\n",
    "        value_code_sub = kbk_section.loc[\n",
    "            (kbk_section.year == year) & (kbk_section.code == code_section_sub), \"mean\"\n",
    "        ].to_list()\n",
    "        if len(value_code_sub):\n",
    "            dict_kbk[\"value_code_sub\"] = value_code_sub[0]\n",
    "        else:\n",
    "            pass\n",
    "        # print('code_type_expenses:', value_code_sub)\n",
    "\n",
    "        value_code_type_expenses = kbk_type.loc[\n",
    "            kbk_type.code == code_type_expenses, \"mean\"\n",
    "        ].to_list()\n",
    "        if len(value_code_type_expenses):\n",
    "            dict_kbk[\"value_code_type_expenses\"] = value_code_type_expenses[0]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # print('value_code_type_expenses:', value_code_type_expenses)\n",
    "        if code_national_project:\n",
    "            list_national_project = kbk_np.loc[\n",
    "                (kbk_np.year == year) & (kbk_np.code == code_national_project),\n",
    "                [\"name_national_project\", \"name_fed_national_project\"],\n",
    "            ].values\n",
    "            # print('list_national_project:', list_national_project)\n",
    "\n",
    "            if len(list_national_project):\n",
    "                dict_kbk[\"name_national_project\"] = list_national_project[0]\n",
    "                dict_kbk[\"name_fed_national_project\"] = list_national_project[1]\n",
    "            else:\n",
    "                pass\n",
    "                # логи\n",
    "\n",
    "        dict_kbk[\"code_main_admin\"] = code_main_admin\n",
    "        dict_kbk[\"code_section_sub\"] = code_section_sub\n",
    "        dict_kbk[\"code_direction_expenses\"] = code_direction_expenses\n",
    "        dict_kbk[\"code_type_expenses\"] = code_type_expenses\n",
    "        dict_kbk[\"code_national_project\"] = code_national_project\n",
    "\n",
    "        return dict_kbk\n",
    "\n",
    "    else:\n",
    "        # print(kbk)\n",
    "        return dict_kbk\n",
    "        # добавить логи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Поиск и замена плохих адресов](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_org = pd.DataFrame()\n",
    "\n",
    "\n",
    "def check_address(address: str, unique: str, cahce_address_customers: dict):\n",
    "    if type(code) != str:\n",
    "        code = None\n",
    "    if type(code_type) != str:\n",
    "        code_type = None\n",
    "\n",
    "    list_check = [\"Российская Федерация\", \"РФ\", \"обл\", \"ул\", \"край\", \"г,\", \"п.\"]\n",
    "    is_nan = type(address) == float\n",
    "    is_telephon = address.replace(\"-\", \"\").replace(\" \", \"\").isdigit()\n",
    "    is_email = (\"@\" in address) and not any([i in address for i in list_check])\n",
    "\n",
    "    need_replace = any([is_nan, is_telephon, is_email])\n",
    "\n",
    "    if not need_replace:\n",
    "        return address\n",
    "    else:\n",
    "        return cahce_address_customers[unique]\n",
    "\n",
    "\n",
    "def apply_chech_address(address):\n",
    "    if type(address) != str:\n",
    "        return True\n",
    "    list_check = [\"Российская Федерация\", \"РФ\", \"обл\", \"ул\", \"край\", \"г,\", \"п.\"]\n",
    "    is_nan = type(address) == float\n",
    "    is_telephon = address.replace(\"-\", \"\").replace(\" \", \"\").isdigit()\n",
    "    is_email = (\"@\" in address) and not any([i in address for i in list_check])\n",
    "\n",
    "    return any([is_nan, is_telephon, is_email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_address = set()\n",
    "# num_bad_address = 0\n",
    "# path = '../data/raw_data/contract/2014/'\n",
    "# for file_name in tqdm(os.listdir(path)):\n",
    "#     file_name = os.path.join(path, file_name)\n",
    "#     df_now = pd.read_csv(file_name, dtype='str', sep=\"|\")\n",
    "\n",
    "#     df_now['result'] = df_now['address_customer'].parallel_apply(apply_chech_address)\n",
    "#     num_bad_address += len(df_now[df_now.result == True])\n",
    "#     bad_address.update(set(df_now[df_now.result == True].address_customer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Декомпозиция адресов](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecompositionAddress:\n",
    "    def __init__(self, path_for_cache: str, year: str):\n",
    "        self.path_for_cache = path_for_cache\n",
    "        self.columns = [\n",
    "            \"country\",\n",
    "            \"regioncity\",\n",
    "            \"regionarea\",\n",
    "            \"district\",\n",
    "            \"settlement\",\n",
    "            \"city\",\n",
    "            \"citydistrict\",\n",
    "            \"locality\",\n",
    "            \"territory\",\n",
    "            \"street\",\n",
    "            \"plot\",\n",
    "            \"building\",\n",
    "            \"apartment\",\n",
    "            \"room\",\n",
    "            \"coef\",\n",
    "        ]\n",
    "        self.extra_columns = [\"address\", \"year\"]\n",
    "        self.year = year\n",
    "\n",
    "        if not os.path.exists(path_for_cache):\n",
    "            pd.DataFrame(columns=self.extra_columns + self.columns).to_csv(\n",
    "                path_for_cache, sep=\"|\", index=False\n",
    "            )\n",
    "\n",
    "        self.dict_cahce = pd.read_csv(\n",
    "            path_for_cache,\n",
    "            sep=\"|\",\n",
    "            dtype=\"str\",\n",
    "            index_col=\"address\",\n",
    "            usecols=self.columns + [self.extra_columns[0]],\n",
    "        ).to_dict(orient=\"index\")\n",
    "\n",
    "    def address_decompose(self, address: str):\n",
    "        if not address or address == \"\" or type(address) != str:\n",
    "            return {key: None for key in self.columns}\n",
    "\n",
    "        if address in self.dict_cahce:\n",
    "            return self.dict_cahce[address]\n",
    "\n",
    "        else:\n",
    "            return self.use_pullenti(address)\n",
    "\n",
    "    def use_pullenti(self, address: str):\n",
    "        dict_res = {key: None for key in self.columns}\n",
    "        process_address = AddressService.process_single_address_text(address)\n",
    "\n",
    "        dict_res[\"coef\"] = process_address.coef\n",
    "\n",
    "        for address_element in process_address.items:\n",
    "            level = str(address_element.level).split(\".\")[1].lower()\n",
    "            element_address = address_element.to_string_min()\n",
    "            dict_res[level] = element_address\n",
    "\n",
    "        self.add_address_to_cache(address, dict_res)\n",
    "        dict_res.pop(\"coef\")\n",
    "        return dict_res\n",
    "\n",
    "    def add_address_to_cache(self, address, dict_result):\n",
    "        self.dict_cahce[address] = dict_result\n",
    "        dict_result_for_df = dict_result.copy()\n",
    "        dict_result_for_df[\"address\"] = address\n",
    "        dict_result_for_df[\"year\"] = self.year\n",
    "        pd.DataFrame(dict_result_for_df, index=[0])[self.extra_columns + self.columns].to_csv(\n",
    "            self.path_for_cache, sep=\"|\", index=False, mode=\"a\", header=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Российская Федерация, 142279, Московская обл, Серпухов г, Оболенск п, ТЕР. КВАРТАЛ А</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Российская Федерация, 140578, Московская обл, Озёры г, Емельяновка д, УЛИЦА САДОВАЯ</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Российская Федерация, 143968, Московская обл, Реутов г, Победы, 33</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Российская Федерация, 141930, Московская обл, Талдом г, Вербилки рп, УЛИЦА ЗАБЫРИНА, 4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Российская Федерация, 141900, Московская обл, Талдом г, ПЛОЩАДЬ К.МАРКСА, 12</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>630049 г. Новосибирск, ул. Дуси Ковальчук, д. 272/2</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>Российская Федерация, 630089, Новосибирская обл, Новосибирск г, ул АДРИЕНА ЛЕЖЕНА, 5/1</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>630090, г.Новосибирск, ул. Октябрьская, 42</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>Российская Федерация, 633623, Новосибирская обл, Сузун рп, ул ПАРТИЗАНСКАЯ, 214</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>630028, Российская Федерация, Новосибирская обл, г. Новосибирк, Хитровская, 34, ОКАТО: 50401379000</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11852 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  address  \\\n",
       "0                    Российская Федерация, 142279, Московская обл, Серпухов г, Оболенск п, ТЕР. КВАРТАЛ А   \n",
       "1                     Российская Федерация, 140578, Московская обл, Озёры г, Емельяновка д, УЛИЦА САДОВАЯ   \n",
       "2                                      Российская Федерация, 143968, Московская обл, Реутов г, Победы, 33   \n",
       "3                  Российская Федерация, 141930, Московская обл, Талдом г, Вербилки рп, УЛИЦА ЗАБЫРИНА, 4   \n",
       "4                            Российская Федерация, 141900, Московская обл, Талдом г, ПЛОЩАДЬ К.МАРКСА, 12   \n",
       "...                                                                                                   ...   \n",
       "11847                                                 630049 г. Новосибирск, ул. Дуси Ковальчук, д. 272/2   \n",
       "11848              Российская Федерация, 630089, Новосибирская обл, Новосибирск г, ул АДРИЕНА ЛЕЖЕНА, 5/1   \n",
       "11849                                                          630090, г.Новосибирск, ул. Октябрьская, 42   \n",
       "11850                     Российская Федерация, 633623, Новосибирская обл, Сузун рп, ул ПАРТИЗАНСКАЯ, 214   \n",
       "11851  630028, Российская Федерация, Новосибирская обл, г. Новосибирк, Хитровская, 34, ОКАТО: 50401379000   \n",
       "\n",
       "      country  \n",
       "0      Россия  \n",
       "1      Россия  \n",
       "2      Россия  \n",
       "3         NaN  \n",
       "4      Россия  \n",
       "...       ...  \n",
       "11847  Россия  \n",
       "11848  Россия  \n",
       "11849  Россия  \n",
       "11850  Россия  \n",
       "11851  Россия  \n",
       "\n",
       "[11852 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\n",
    "    \"../data/cache/cache_address.csv\", sep=\"|\", dtype=\"str\", usecols=[\"address\", \"country\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dec = DecompositionAddress(path_for_cache=\"../data/cache/cache_address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(df.address.unique()):\n",
    "#     address_dec.address_decompose(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_address = AddressService.process_single_address_text(\n",
    "#     \"Российская Федерация, 678280, Саха /Якутия/ Респ, Сунтарский у, Сарданга с, УЛ. СЕМЕНА СЕМЕНОВА, Д.43\"\n",
    "# )\n",
    "# for address_element in process_address.items:\n",
    "#     print(\"level\", address_element.level)\n",
    "#     print(address_element.to_string_min())\n",
    "# print(\"coef:\", process_address.coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Метод для обработки ORG](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'code_type', 'access_blocking', 'full_name', 'short_name',\n",
      "       'adress', 'code_registr', 'date_registration', 'date_last_change',\n",
      "       'inn', 'kpp', 'ogrn', 'oktmo', 'location', 'iky', 'date_iky',\n",
      "       'code_okfs', 'name_property', 'okpf_code', 'okopf_name', 'credentials',\n",
      "       'date_registration_tax', 'organization_type', 'organization_level',\n",
      "       'okpo_code', 'okfd_code', 'budget_code', 'budget_name', 'telephone',\n",
      "       'fax', 'postal_adress', 'email', 'site', 'contact_person', 'time_zone'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4499, 35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw_data/org/2014_1/0.csv\", sep=\"|\", dtype=\"str\")\n",
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    \"code\",\n",
    "    \"code_type\",\n",
    "    \"access_blocking\",\n",
    "    \"full_name\",\n",
    "    \"short_name\",\n",
    "    \"address\",\n",
    "    \"code_registr\",\n",
    "    \"date_registration\",\n",
    "    \"date_last_change\",\n",
    "    \"inn\",\n",
    "    \"kpp\",\n",
    "    \"ogrn\",\n",
    "    \"oktmo\",\n",
    "    \"location\",\n",
    "    \"iky\",\n",
    "    \"date_iky\",\n",
    "    \"code_okfs\",\n",
    "    \"name_property\",\n",
    "    \"okpf_code\",\n",
    "    \"okopf_name\",\n",
    "    \"credentials\",\n",
    "    \"date_registration_tax\",\n",
    "    \"organization_type\",\n",
    "    \"organization_level\",\n",
    "    \"okpo_code\",\n",
    "    \"okfd_code\",\n",
    "    \"budget_code\",\n",
    "    \"budget_name\",\n",
    "    \"telephone\",\n",
    "    \"fax\",\n",
    "    \"postal_address\",\n",
    "    \"email\",\n",
    "    \"site\",\n",
    "    \"contact_person\",\n",
    "    \"time_zone\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_dec = DecompositionAddress(path_for_cache=\"../data/cache/cache_aderess.csv\")\n",
    "\n",
    "\n",
    "def processing_date_org(df: Series, columns: list):\n",
    "    dict_result = {}\n",
    "    # если мы получает nan при обращении к дате в DataFrame, то\n",
    "    # np.nan == nan возращает False, однако у nan type float, когда у всех дат str\n",
    "    inn = df[\"inn\"]\n",
    "    # unique_code = df[\"code\"] + df['code_type']\n",
    "\n",
    "    date_list = [i for i in columns if \"date\" in i]\n",
    "\n",
    "    for date_type in date_list:\n",
    "        dict_result[date_type] = date_extract(df[date_type])\n",
    "\n",
    "    dict_result[\"organization_level\"] = fillna_organization_level(\n",
    "        df[\"organization_level\"], df[\"full_name\"], df[\"inn\"]\n",
    "    )\n",
    "\n",
    "    return pd.Series(dict_result)[columns].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_level = [\n",
    "    \"country\",\n",
    "    \"regioncity\",\n",
    "    \"regionarea\",\n",
    "    \"district\",\n",
    "    \"settlement\",\n",
    "    \"city\",\n",
    "    \"citydistrict\",\n",
    "    \"locality\",\n",
    "    \"territory\",\n",
    "    \"street\",\n",
    "    \"plot\",\n",
    "    \"building\",\n",
    "    \"apartment\",\n",
    "    \"room\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\n",
    "#     \"date_registration\",\n",
    "#     \"date_last_change\",\n",
    "#     \"date_registration_tax\",\n",
    "#     \"date_iky\",\n",
    "#     \"organization_level\",\n",
    "# ]\n",
    "# df = pd.read_csv(\"../data/raw_data/org/2014_1/5.csv\", sep=\"|\", dtype=\"str\")\n",
    "# df_copy = df.copy()\n",
    "\n",
    "# df_copy[columns] = df_copy.apply(\n",
    "#     lambda x: processing_date_org(x, columns=columns), axis=1, result_type=\"expand\"\n",
    "# )\n",
    "# df_copy[columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_test = \"../data/raw_data/org/2014_1/\"\n",
    "# prob = []\n",
    "# num_problem = 0\n",
    "# df_buffer = pd.DataFrame(columns=[\"organization_level\", \"full_name\", \"inn\"])\n",
    "# for file_name in tqdm(sorted(os.listdir(path_test), key=lambda x: int(x.removesuffix(\".csv\")))):\n",
    "#     df_test_now = pd.read_csv(os.path.join(path_test, file_name), sep=\"|\", dtype=\"str\")\n",
    "#     df_test_now[columns] = df_test_now.parallel_apply(\n",
    "#         lambda x: processing_date_org(x, columns=columns), axis=1, result_type=\"expand\"\n",
    "#     )\n",
    "#     problem_level_org = df_test_now.organization_level.isnull().sum()\n",
    "#     num_problem += problem_level_org\n",
    "#     if problem_level_org:\n",
    "#         prob.append((file_name, problem_level_org))\n",
    "#         df_buffer = pd.concat(\n",
    "#             [\n",
    "#                 df_buffer,\n",
    "#                 df_test_now.loc[\n",
    "#                     df_test_now.organization_level.isnull(),\n",
    "#                     [\"organization_level\", \"full_name\", \"inn\"],\n",
    "#                 ],\n",
    "#             ]\n",
    "#         )\n",
    "# num_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Метод для обработки contract](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_contract', 'address_customer', 'full_name_customer',\n",
       "       'short_name_customer', 'code', 'code_type', 'id_customer',\n",
       "       'inn_customer', 'kpp_customer', 'code_form_org', 'okpo_code',\n",
       "       'municipal_code', 'budget_name', 'extrabudget_name', 'budget_level',\n",
       "       'contract_status', 'notice', 'ikz_code', 'id_contract_electronic',\n",
       "       'unique_number_plan', 'method_determinig_supplier', 'date_summarizing',\n",
       "       'date_posting', 'grouds_single_supplier', 'document_details',\n",
       "       'info_support', 'date_contract', 'date_performance',\n",
       "       'date_contract_registry', 'date_update_registry',\n",
       "       'date_start_performance', 'date_end_performance', 'contract_item',\n",
       "       'contract_price', 'contract_price_nds', 'prepayment_amount',\n",
       "       'performance_security', 'size_performance_quality', 'warranty_period',\n",
       "       'place_performance', 'full_name_supplier', 'inn_supplier',\n",
       "       'kpp_supplier', 'code_okpo_supplier', 'date_registration_supplier',\n",
       "       'country_supplier', 'code_country_supplier', 'address_supplier',\n",
       "       'postal_address_supplier', 'contact', 'status_supplier', 'kbk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw_data/contract/2014/0.csv\", sep=\"|\", dtype=\"str\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_summarizing',\n",
       " 'date_posting',\n",
       " 'date_contract',\n",
       " 'date_performance',\n",
       " 'date_contract_registry',\n",
       " 'date_update_registry',\n",
       " 'date_start_performance',\n",
       " 'date_end_performance',\n",
       " 'date_registration_supplier']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df.columns if \"date\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_date_contract(df: Series, columns: list):\n",
    "    year = 2014\n",
    "    dict_result = {}\n",
    "\n",
    "    date_list = [i for i in columns if \"date\" in i]\n",
    "\n",
    "    for date_type in date_list:\n",
    "        dict_result[date_type] = date_extract(df[date_type])\n",
    "\n",
    "    dict_result[\"organization_level\"] = fillna_organization_level(\n",
    "        df[\"budget_level\"], df[\"full_name_customer\"], df[\"inn_customer\"]\n",
    "    )\n",
    "\n",
    "    for date in [\n",
    "        \"find_date_contract\",\n",
    "        \"date_summarizing\",\n",
    "        \"date_posting\",\n",
    "        \"date_performance\",\n",
    "        \"date_end_performance\",\n",
    "        \"date_contract_registry\",\n",
    "    ]:\n",
    "        if type(dict_result[date]) == datetime.date:\n",
    "            year = str(dict_result[date].year)\n",
    "            break\n",
    "\n",
    "    dict_result.update(extract_data_from_kbk(df[\"kbk\"], year))\n",
    "\n",
    "    return pd.Series(dict_result)[columns].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\n",
    "#     \"date_summarizing\",\n",
    "#     \"date_posting\",\n",
    "#     \"date_contract\",\n",
    "#     \"date_performance\",\n",
    "#     \"date_contract_registry\",\n",
    "#     \"date_update_registry\",\n",
    "#     \"date_start_performance\",\n",
    "#     \"date_end_performance\",\n",
    "#     \"date_registration_supplier\",\n",
    "#     \"code_main_admin\",\n",
    "#     \"code_section_sub\",\n",
    "#     \"code_direction_expenses\",\n",
    "#     \"code_type_expenses\",\n",
    "#     \"code_national_project\",\n",
    "#     \"value_code_section\",\n",
    "#     \"value_code_sub\",\n",
    "#     \"value_code_type_expenses\",\n",
    "#     \"name_national_project\",\n",
    "#     \"name_fed_national_project\",\n",
    "#     \"organization_level\",\n",
    "# ]\n",
    "# path_test = \"../data/raw_data/contract/2014_1/\"\n",
    "# prob = []\n",
    "# num_problem = 0\n",
    "# df_buffer = pd.DataFrame(\n",
    "#     columns=[\"budget_name\", \"budget_level\", \"full_name_customer\", \"inn_customer\"]\n",
    "# )\n",
    "# for file_name in tqdm(sorted(os.listdir(path_test), key=lambda x: int(x.removesuffix(\".csv\")))):\n",
    "#     df_test_now = pd.read_csv(os.path.join(path_test, file_name), sep=\"|\", dtype=\"str\")\n",
    "#     df_test_now[columns] = df_test_now.parallel_apply(\n",
    "#         lambda x: processing_date_contract(x, columns=columns), axis=1, result_type=\"expand\"\n",
    "#     )\n",
    "#     problem_level_org = df_test_now.organization_level.isnull().sum()\n",
    "#     num_problem += problem_level_org\n",
    "#     if problem_level_org:\n",
    "#         prob.append((file_name, problem_level_org))\n",
    "#         df_buffer = pd.concat(\n",
    "#             [\n",
    "#                 df_buffer,\n",
    "#                 df_test_now.loc[\n",
    "#                     df_test_now.organization_level.isnull(),\n",
    "#                     [\"budget_name\", \"budget_level\", \"full_name_customer\", \"inn_customer\"],\n",
    "#                 ],\n",
    "#             ]\n",
    "#         )\n",
    "# num_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Класс для обработки данных](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_cache_address: str,\n",
    "        path_cache_org_address: str,\n",
    "        path_kbk_table: str,\n",
    "        default_year_for_kbk: str,\n",
    "    ):\n",
    "        self.address_dec = DecompositionAddress(path_for_cache=path_cache_address, year=default_year_for_kbk)\n",
    "\n",
    "        self.path_cache_org_address = path_cache_org_address\n",
    "        if not os.path.exists(path_cache_org_address):\n",
    "            pd.DataFrame(columns=[\"code\", \"code_type\", \"address\", \"year\"]).to_csv(\n",
    "                path_cache_org_address, sep=\"|\", index=False\n",
    "            )\n",
    "\n",
    "        # подготовка кэша адрессов\n",
    "        df_cahce = pd.read_csv(path_cache_org_address, sep=\"|\", dtype=\"str\")\n",
    "        self.columns_cache = list(df_cahce.columns)\n",
    "        df_cahce[\"unique\"] = df_cahce[\"code\"] + \"_\" + df_cahce[\"code_type\"]\n",
    "        df_cahce = df_cahce[[\"unique\", \"address\"]].set_index(\"unique\")\n",
    "\n",
    "        self.cache_org_address = df_cahce.to_dict(orient=\"index\")\n",
    "        self.kbk_type = pd.read_excel(path_kbk_table, sheet_name=\"type\", dtype=\"str\")\n",
    "        self.kbk_np = pd.read_excel(path_kbk_table, sheet_name=\"np\", dtype=\"str\")\n",
    "        self.kbk_section = pd.read_excel(path_kbk_table, sheet_name=\"section\", dtype=\"str\")\n",
    "\n",
    "        self.default_year_for_kbk = default_year_for_kbk\n",
    "\n",
    "        self.address_level = [\n",
    "            \"country\",\n",
    "            \"regioncity\",\n",
    "            \"regionarea\",\n",
    "            \"district\",\n",
    "            \"settlement\",\n",
    "            \"city\",\n",
    "            \"citydistrict\",\n",
    "            \"locality\",\n",
    "            \"territory\",\n",
    "            \"street\",\n",
    "            \"plot\",\n",
    "            \"building\",\n",
    "            \"apartment\",\n",
    "            \"room\",\n",
    "        ]\n",
    "\n",
    "    def date_extract(self, date: str):\n",
    "        if not date or date == \"--.--.----\" or type(date) != str:\n",
    "            return None\n",
    "\n",
    "        date = date.replace(\"Загрузка ...\", \"\").strip()\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date, \"%d.%m.%Y\").date()\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date[:10], \"%d.%m.%Y\").date()\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date.split()[0], \"%d.%m.%Y\").date()\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        for key, value in dict_month.items():\n",
    "            if key in date:\n",
    "                date = date.replace(key, value)\n",
    "                date = \".\".join(date.split())\n",
    "\n",
    "        date = date.split(\".\")\n",
    "\n",
    "        if len(date) == 2:\n",
    "            date = \".\".join([\"01\"] + date)\n",
    "            return datetime.datetime.strptime(date[:10], \"%d.%m.%Y\").date()\n",
    "\n",
    "    def fillna_organization_level(\n",
    "        self, budget_level: str, full_name_customer: str, inn_customer: str\n",
    "    ):\n",
    "        if type(budget_level) != str:\n",
    "            budget_level = None\n",
    "        elif type(budget_level) == str:\n",
    "            budget_level = budget_level.lower()\n",
    "\n",
    "        if type(full_name_customer) != str:\n",
    "            full_name_customer = None\n",
    "        elif type(full_name_customer) == str:\n",
    "            full_name_customer = full_name_customer.lower()\n",
    "\n",
    "        if type(inn_customer) != str:\n",
    "            inn_customer = None\n",
    "\n",
    "        if budget_level:\n",
    "            for list_name, name in zip(\n",
    "                [list_local, list_sub, list_fed], [\"местный\", \"субъектовый\", \"федеральный\"]\n",
    "            ):\n",
    "                for name_trigger in list_name:\n",
    "                    if name_trigger.lower() in budget_level:\n",
    "                        return name\n",
    "\n",
    "        # если не получилось выделить данные из budget_level попробуем сделать это с full_name_customer\n",
    "        if full_name_customer:\n",
    "            for list_name, name in zip(\n",
    "                [list_fed_2, list_local_2, list_sub_2, list_anothe],\n",
    "                [\"федеральный\", \"местный\", \"субъектовый\", \"иное\"],\n",
    "            ):\n",
    "                for name_trigger in list_name:\n",
    "                    if name_trigger.lower() in full_name_customer:\n",
    "                        return name\n",
    "\n",
    "            for list_name, name in zip(\n",
    "                [list_fed_3, list_local_3, list_sub_3],\n",
    "                [\"федеральный\", \"местный\", \"субъектовый\", \"иное\"],\n",
    "            ):\n",
    "                for name_trigger in list_name:\n",
    "                    if name_trigger.lower() in full_name_customer:\n",
    "                        return name\n",
    "\n",
    "            if (\n",
    "                \"администрац\" in full_name_customer\n",
    "                or \"комитет по управлению имуществом\" in full_name_customer\n",
    "            ) and not all(\n",
    "                [\n",
    "                    i in full_name_customer\n",
    "                    for i in [\"моксв\", \"севастопол\" \"президент\", \"санкт-петербур\"]\n",
    "                ]\n",
    "            ):\n",
    "                return \"местный\"\n",
    "\n",
    "            if \"городская дума\" in full_name_customer and \"моксв\" not in full_name_customer:\n",
    "                return \"местный\"\n",
    "\n",
    "        if inn_customer:\n",
    "            for inn_dict, name in zip(\n",
    "                [inn_mun, inn_sub, inn_fed, inn_another],\n",
    "                [\"местный\", \"субъектовый\", \"федеральный\", \"иное\"],\n",
    "            ):\n",
    "                for inn in inn_dict.keys():\n",
    "                    if inn == inn_customer:\n",
    "                        return name\n",
    "        # добавить логги\n",
    "\n",
    "        return None\n",
    "\n",
    "    def extract_data_from_kbk(self, kbk, year):\n",
    "        dict_kbk = {\n",
    "            \"code_main_admin\": None,\n",
    "            \"code_section_sub\": None,\n",
    "            \"code_direction_expenses\": None,\n",
    "            \"code_type_expenses\": None,\n",
    "            \"code_national_project\": None,\n",
    "            \"value_code_section\": None,\n",
    "            \"value_code_sub\": None,\n",
    "            \"value_code_type_expenses\": None,\n",
    "            \"name_national_project\": None,\n",
    "            \"name_fed_national_project\": None,\n",
    "        }\n",
    "        if not kbk or type(kbk) != str:\n",
    "            return dict_kbk\n",
    "\n",
    "        if len(kbk) == 3 or kbk[:-3] == \"0\" * 17:\n",
    "            code_type_expenses = kbk[-3:]\n",
    "            value_code_type_expenses = kbk_type.loc[\n",
    "                kbk_type.code == code_type_expenses, \"mean\"\n",
    "            ].to_list()\n",
    "\n",
    "            if len(value_code_type_expenses):\n",
    "                dict_kbk[\"value_code_type_expenses\"] = value_code_type_expenses[0]\n",
    "            else:\n",
    "                pass\n",
    "                # логи\n",
    "            dict_kbk[\"code_type_expenses\"] = code_type_expenses\n",
    "            return dict_kbk\n",
    "\n",
    "        elif len(kbk) == 20:\n",
    "            kbk_search = re.compile(r\"(\\S\\S\\S)(\\S\\S\\S\\S)(\\S\\S\\S\\S\\S\\S\\S\\S\\S\\S)(\\S\\S\\S)\")\n",
    "            kbk_find = kbk_search.search(kbk)\n",
    "\n",
    "            # код главного распоредителя бюджетных средств\n",
    "            code_main_admin = kbk_find.group(1)\n",
    "            # print('Код ГРС:', code_main_admin)\n",
    "            # код раздела и подраздела\n",
    "            code_section_sub = kbk_find.group(2)\n",
    "            # print('Код раздела и подраздела:', code_section_sub)\n",
    "            # код целевой статьи\n",
    "            code_direction_expenses = kbk_find.group(3)\n",
    "            # print('Код целевой статьи:', code_direction_expenses)\n",
    "            # код вида расходов\n",
    "            code_type_expenses = kbk_find.group(4)\n",
    "            # print('Код вида расходов:', code_type_expenses)\n",
    "            # код национального проекта\n",
    "            code_national_project = (\n",
    "                code_direction_expenses[3:5] if not code_direction_expenses[3].isdigit() else None\n",
    "            )\n",
    "            # print('Код национального проекта:', code_national_project)\n",
    "\n",
    "            value_code_section = kbk_section.loc[\n",
    "                (kbk_section.year == year) & (kbk_section.code == code_section_sub[:2]), \"mean\"\n",
    "            ].to_list()\n",
    "            if len(value_code_section):\n",
    "                dict_kbk[\"value_code_section\"] = value_code_section[0]\n",
    "            else:\n",
    "                pass\n",
    "            # print('value_code_section:', value_code_section)\n",
    "\n",
    "            value_code_sub = kbk_section.loc[\n",
    "                (kbk_section.year == year) & (kbk_section.code == code_section_sub), \"mean\"\n",
    "            ].to_list()\n",
    "            if len(value_code_sub):\n",
    "                dict_kbk[\"value_code_sub\"] = value_code_sub[0]\n",
    "            else:\n",
    "                pass\n",
    "            # print('code_type_expenses:', value_code_sub)\n",
    "\n",
    "            value_code_type_expenses = kbk_type.loc[\n",
    "                kbk_type.code == code_type_expenses, \"mean\"\n",
    "            ].to_list()\n",
    "            if len(value_code_type_expenses):\n",
    "                dict_kbk[\"value_code_type_expenses\"] = value_code_type_expenses[0]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # print('value_code_type_expenses:', value_code_type_expenses)\n",
    "            if code_national_project:\n",
    "                list_national_project = kbk_np.loc[\n",
    "                    (kbk_np.year == year) & (kbk_np.code == code_national_project),\n",
    "                    [\"name_national_project\", \"name_fed_national_project\"],\n",
    "                ].values\n",
    "                # print('list_national_project:', list_national_project)\n",
    "\n",
    "                if len(list_national_project):\n",
    "                    dict_kbk[\"name_national_project\"] = list_national_project[0]\n",
    "                    dict_kbk[\"name_fed_national_project\"] = list_national_project[1]\n",
    "                else:\n",
    "                    pass\n",
    "                    # логи\n",
    "\n",
    "            dict_kbk[\"code_main_admin\"] = code_main_admin\n",
    "            dict_kbk[\"code_section_sub\"] = code_section_sub\n",
    "            dict_kbk[\"code_direction_expenses\"] = code_direction_expenses\n",
    "            dict_kbk[\"code_type_expenses\"] = code_type_expenses\n",
    "            dict_kbk[\"code_national_project\"] = code_national_project\n",
    "\n",
    "            return dict_kbk\n",
    "\n",
    "        else:\n",
    "            # print(kbk)\n",
    "            return dict_kbk\n",
    "            # добавить логи\n",
    "\n",
    "    def check_address(self, address: str, code: str, code_type: str):\n",
    "        if type(code) != str or code == \"\":\n",
    "            return address\n",
    "        if type(code_type) != str or code_type == \"\":\n",
    "            return address\n",
    "        if type(address) != str:\n",
    "            address = \"\"\n",
    "\n",
    "        list_check = [\"Российская Федерация\", \"РФ\", \"обл\", \"ул\", \"край\", \"г,\", \"п.\"]\n",
    "        is_nan = type(address) == float\n",
    "        is_telephon = address.replace(\"-\", \"\").replace(\" \", \"\").isdigit()\n",
    "        is_email = (\"@\" in address) and not any([i in address for i in list_check])\n",
    "        is_empty_string = address == \"\"\n",
    "\n",
    "        need_replace = any([is_nan, is_telephon, is_email, is_empty_string])\n",
    "\n",
    "        if not need_replace:\n",
    "            return address\n",
    "        else:\n",
    "            unique = code + \"_\" + code_type\n",
    "            return self.cache_org_address.get(unique)\n",
    "\n",
    "    def processing_date_org(self, df: Series, columns: list):\n",
    "        dict_result = {}\n",
    "        # если мы получает nan при обращении к дате в DataFrame, то\n",
    "        # np.nan == nan возращает False, однако у nan type float, когда у всех дат str\n",
    "        # unique_code = df[\"code\"] + df['code_type']\n",
    "        date_list = [i for i in columns if \"date\" in i]\n",
    "        for date_type in date_list:\n",
    "            dict_result[date_type] = date_extract(df[date_type])\n",
    "        for date_type, prefix_addres in zip([\"address_customer\", \"postal_address\"], [\"c\", \"pc\"]):\n",
    "            dict_result_address = self.address_dec.address_decompose(df[date_type])\n",
    "            for key, value in dict_result_address.items():\n",
    "                dict_result[f\"{prefix_addres}_{key}\"] = value\n",
    "        dict_result[\"organization_level\"] = fillna_organization_level(\n",
    "            df[\"organization_level\"], df[\"full_name_customer\"], df[\"inn_customer\"]\n",
    "        )\n",
    "\n",
    "        return pd.Series(dict_result)[columns].to_list()\n",
    "\n",
    "    def processing_date_contract(self, df: Series, columns: list):\n",
    "        dict_result = {}\n",
    "        year = self.default_year_for_kbk\n",
    "        date_list = [i for i in columns if \"date\" in i]\n",
    "\n",
    "        for date_type in date_list:\n",
    "            dict_result[date_type] = date_extract(df[date_type])\n",
    "\n",
    "        for address_type, prefix_addres in zip(\n",
    "            [\"address_customer\", \"address_supplier\", \"postal_address_supplier\"], [\"c\", \"s\", \"ps\"]\n",
    "        ):\n",
    "            address = df[address_type]\n",
    "            if address_type == \"address_customer\":\n",
    "                address = self.check_address(address, code=df[\"code\"], code_type=df[\"code_type\"])\n",
    "\n",
    "            dict_result_address = self.address_dec.address_decompose(address)\n",
    "            for key, value in dict_result_address.items():\n",
    "                dict_result[f\"{prefix_addres}_{key}\"] = value\n",
    "\n",
    "        dict_result[\"organization_level\"] = fillna_organization_level(\n",
    "            df[\"budget_level\"], df[\"full_name_customer\"], df[\"inn_customer\"]\n",
    "        )\n",
    "\n",
    "        for date in [\n",
    "            \"date_contract\",\n",
    "            \"date_summarizing\",\n",
    "            \"date_posting\",\n",
    "            \"date_performance\",\n",
    "            \"date_end_performance\",\n",
    "            \"date_contract_registry\",\n",
    "        ]:\n",
    "            if type(dict_result[date]) == datetime.date:\n",
    "                year = str(dict_result[date].year)\n",
    "                break\n",
    "\n",
    "        dict_result.update(extract_data_from_kbk(df[\"kbk\"], year))\n",
    "\n",
    "        return pd.Series(dict_result)[columns].to_list()\n",
    "\n",
    "    def add_new_address_to_cache(self, df: DataFrame):\n",
    "        df_address = df[[\"address_customer\", \"code\", \"code_type\"]]\n",
    "        for index in df_address.index:\n",
    "            address = df_address.loc[index, \"address_customer\"]\n",
    "            code = df_address.loc[index, \"code\"]\n",
    "            code_type = df_address.loc[index, \"code_type\"]\n",
    "            if type(code) != str or type(code_type) != str or type(address) != str:\n",
    "                continue\n",
    "\n",
    "            unique = code + \"_\" + code_type\n",
    "            if not unique in self.cache_org_address:\n",
    "                self.cache_org_address[unique] = address\n",
    "\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"address\": [address],\n",
    "                        \"code\": [code],\n",
    "                        \"code_type\": [code_type],\n",
    "                        \"year\": [self.default_year_for_kbk],\n",
    "                    },\n",
    "                    index=[0],\n",
    "                )[self.columns_cache].to_csv(\n",
    "                    self.path_cache_org_address, mode=\"a\", index=False, header=False, sep=\"|\"\n",
    "                )\n",
    "\n",
    "    def run_org(self, path_input: str, path_output: str):\n",
    "        df = pd.read_csv(path_input, sep=\"|\", dtype=\"str\")\n",
    "        columns = [\n",
    "            \"date_registration\",\n",
    "            \"date_last_change\",\n",
    "            \"date_registration_tax\",\n",
    "            \"date_iky\",\n",
    "            \"organization_level\",\n",
    "        ] + [\n",
    "            prefix + \"_\" + address_level\n",
    "            for prefix in [\"c\", \"pc\"]\n",
    "            for address_level in self.address_level\n",
    "        ]\n",
    "        df[columns] = df.apply(\n",
    "            lambda x: self.processing_date_org(x, columns=columns), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "        self.add_new_address_to_cache(df)\n",
    "        df.to_csv(path_output, sep=\"|\", index=False)\n",
    "\n",
    "    def run_contract(self, path_input: str, path_output: str):\n",
    "        df = pd.read_csv(path_input, sep=\"|\", dtype=\"str\")\n",
    "        columns = [\n",
    "            \"date_summarizing\",\n",
    "            \"date_posting\",\n",
    "            \"date_contract\",\n",
    "            \"date_performance\",\n",
    "            \"date_contract_registry\",\n",
    "            \"date_update_registry\",\n",
    "            \"date_start_performance\",\n",
    "            \"date_end_performance\",\n",
    "            \"date_registration_supplier\",\n",
    "            \"code_main_admin\",\n",
    "            \"code_section_sub\",\n",
    "            \"code_direction_expenses\",\n",
    "            \"code_type_expenses\",\n",
    "            \"code_national_project\",\n",
    "            \"value_code_section\",\n",
    "            \"value_code_sub\",\n",
    "            \"value_code_type_expenses\",\n",
    "            \"name_national_project\",\n",
    "            \"name_fed_national_project\",\n",
    "            \"organization_level\",\n",
    "        ] + [\n",
    "            prefix + \"_\" + address_level\n",
    "            for prefix in [\"c\", \"s\", \"ps\"]\n",
    "            for address_level in self.address_level\n",
    "        ]\n",
    "        df[columns] = df.apply(\n",
    "            lambda x: self.processing_date_contract(x, columns=columns),\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "        df.to_csv(path_output, sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_date = ProcessingData(\n",
    "    path_cache_address=\"../data/cache/cache_address.csv\",\n",
    "    path_cache_org_address=\"../data/cache/cache_org_address.csv\",\n",
    "    path_kbk_table=\"../data/kbk.xlsx\",\n",
    "    default_year_for_kbk=\"2014\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [04:29<2:10:28, 134.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m file_name_input \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_input, file_name)\n\u001b[1;32m      6\u001b[0m file_name_output \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_path, file_name)\n\u001b[0;32m----> 7\u001b[0m processing_date\u001b[39m.\u001b[39;49mrun_org(file_name_input, file_name_output)\n",
      "Cell \u001b[0;32mIn[96], line 369\u001b[0m, in \u001b[0;36mProcessingData.run_org\u001b[0;34m(self, path_input, path_output)\u001b[0m\n\u001b[1;32m    357\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path_input, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    358\u001b[0m columns \u001b[39m=\u001b[39m [\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdate_registration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdate_last_change\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[39mfor\u001b[39;00m address_level \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddress_level\n\u001b[1;32m    368\u001b[0m ]\n\u001b[0;32m--> 369\u001b[0m df[columns] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    370\u001b[0m     \u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessing_date_org(x, columns\u001b[39m=\u001b[39;49mcolumns), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, result_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mexpand\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    371\u001b[0m )\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_new_address_to_cache(df)\n\u001b[1;32m    373\u001b[0m df\u001b[39m.\u001b[39mto_csv(path_output, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/contract-Fr7eyqb1-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/contract-Fr7eyqb1-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/contract-Fr7eyqb1-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/contract-Fr7eyqb1-py3.10/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[96], line 370\u001b[0m, in \u001b[0;36mProcessingData.run_org.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    357\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path_input, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    358\u001b[0m columns \u001b[39m=\u001b[39m [\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdate_registration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdate_last_change\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[39mfor\u001b[39;00m address_level \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddress_level\n\u001b[1;32m    368\u001b[0m ]\n\u001b[1;32m    369\u001b[0m df[columns] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessing_date_org(x, columns\u001b[39m=\u001b[39;49mcolumns), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, result_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpand\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m )\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_new_address_to_cache(df)\n\u001b[1;32m    373\u001b[0m df\u001b[39m.\u001b[39mto_csv(path_output, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[96], line 283\u001b[0m, in \u001b[0;36mProcessingData.processing_date_org\u001b[0;34m(self, df, columns)\u001b[0m\n\u001b[1;32m    281\u001b[0m     dict_result[date_type] \u001b[39m=\u001b[39m date_extract(df[date_type])\n\u001b[1;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m date_type, prefix_addres \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39maddress_customer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpostal_address\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpc\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m--> 283\u001b[0m     dict_result_address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddress_dec\u001b[39m.\u001b[39;49maddress_decompose(df[date_type])\n\u001b[1;32m    284\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dict_result_address\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    285\u001b[0m         dict_result[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix_addres\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m value\n",
      "Cell \u001b[0;32mIn[73], line 45\u001b[0m, in \u001b[0;36mDecompositionAddress.address_decompose\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdict_cahce[address]\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_pullenti(address)\n",
      "Cell \u001b[0;32mIn[73], line 49\u001b[0m, in \u001b[0;36mDecompositionAddress.use_pullenti\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muse_pullenti\u001b[39m(\u001b[39mself\u001b[39m, address: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     48\u001b[0m     dict_res \u001b[39m=\u001b[39m {key: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns}\n\u001b[0;32m---> 49\u001b[0m     process_address \u001b[39m=\u001b[39m AddressService\u001b[39m.\u001b[39;49mprocess_single_address_text(address)\n\u001b[1;32m     51\u001b[0m     dict_res[\u001b[39m\"\u001b[39m\u001b[39mcoef\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m process_address\u001b[39m.\u001b[39mcoef\n\u001b[1;32m     53\u001b[0m     \u001b[39mfor\u001b[39;00m address_element \u001b[39min\u001b[39;00m process_address\u001b[39m.\u001b[39mitems:\n",
      "File \u001b[0;32m/home/harddisk/projects/contract/notebooks/pullenti/address/AddressService.py:209\u001b[0m, in \u001b[0;36mAddressService.process_single_address_text\u001b[0;34m(txt, pars)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m: \n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m (ServerHelper\u001b[39m.\u001b[39mSERVER_URI \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m): \n\u001b[0;32m--> 209\u001b[0m         \u001b[39mreturn\u001b[39;00m ServerHelper\u001b[39m.\u001b[39;49mprocess_single_address_text(txt, pars)\n\u001b[1;32m    210\u001b[0m     sw \u001b[39m=\u001b[39m Stopwatch()\n\u001b[1;32m    211\u001b[0m     sw\u001b[39m.\u001b[39mstart()\n",
      "File \u001b[0;32m/home/harddisk/projects/contract/notebooks/pullenti/address/internal/ServerHelper.py:173\u001b[0m, in \u001b[0;36mServerHelper.process_single_address_text\u001b[0;34m(txt, pars)\u001b[0m\n\u001b[1;32m    171\u001b[0m dat1 \u001b[39m=\u001b[39m [ ]\n\u001b[1;32m    172\u001b[0m \u001b[39mwith\u001b[39;00m ServerHelper\u001b[39m.\u001b[39m__m_lock: \n\u001b[0;32m--> 173\u001b[0m     dat1 \u001b[39m=\u001b[39m web\u001b[39m.\u001b[39;49mupload_data(ServerHelper\u001b[39m.\u001b[39;49mSERVER_URI, dat)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m (dat1 \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(dat1) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m): \n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/harddisk/projects/contract/notebooks/pullenti/unisharp/Misc.py:20\u001b[0m, in \u001b[0;36mWebClient.upload_data\u001b[0;34m(self, addr, dat)\u001b[0m\n\u001b[1;32m     18\u001b[0m connection \u001b[39m=\u001b[39m http\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mHTTPConnection(addr)\n\u001b[1;32m     19\u001b[0m connection\u001b[39m.\u001b[39mrequest(\u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, dat)\n\u001b[0;32m---> 20\u001b[0m response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m     21\u001b[0m res \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mread()\n\u001b[1;32m     22\u001b[0m connection\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_input = \"../data/raw_data/org/2014/\"\n",
    "output_path = \"../data/processed_data/org/2014/\"\n",
    "\n",
    "for file_name in tqdm(sorted(os.listdir(path_input), key= lambda x: int(x.removesuffix('.csv')))):\n",
    "    file_name_input = os.path.join(path_input, file_name)\n",
    "    file_name_output = os.path.join(output_path, file_name)\n",
    "    processing_date.run_org(file_name_input, file_name_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/raw_data/contract/2014/0.csv\"\n",
    "output_path = \"../data/processed_data/contract/2014/0.csv\"\n",
    "processing_date.run_contract(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_path, sep=\"|\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df.number_contract == '0111300015714000030']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kazansport@mail.ru'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_date.check_address(df_new['address_customer'].values[0], code=df_new['code'].values[0], code_type=df_new['code_type'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'786179_Id'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['code'].values[0] + '_' + df_new['code_type'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'786179_Id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processing_date\u001b[39m.\u001b[39;49mcache_org_address[df_new[\u001b[39m'\u001b[39;49m\u001b[39mcode\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m df_new[\u001b[39m'\u001b[39;49m\u001b[39mcode_type\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m]]\n",
      "\u001b[0;31mKeyError\u001b[0m: '786179_Id'"
     ]
    }
   ],
   "source": [
    "processing_date.cache_org_address[df_new['code'].values[0] + '_' + df_new['code_type'].values[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contract-Fr7eyqb1-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
